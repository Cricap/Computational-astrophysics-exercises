{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Cosmological Parameters From Type Ia Supernova Data\n",
    "\n",
    "In this exercise we will work with some type Ia supernova data.  This is part of the data used to determine that Universe's expansion is accelerating.\n",
    "\n",
    "Data obtained is from the Supernova Cosmology Project at:\n",
    "http://supernova.lbl.gov/union/descriptions.html#Magvsz\n",
    "\n",
    "**Background:**\n",
    "\n",
    "The observed magnitude of an object with luminosity $L$ is\n",
    "\n",
    "$m = - 2.5 \\log\\left( \\frac{L}{2\\pi D_L^2} \\right) + m_o = 5 \\log\\left( D_L \\right) + 2.5 \\log\\left( L \\right) + m_o$\n",
    "\n",
    "where $D_L$ is the luminosity distance and $m_o$ is the zero point, a constant.  The peak luminosity of a type Ia supernovae \n",
    "is directly related to the width of its lightcurve and its color.  In this data set, the correction to a standard candle has already been done by fitting light curves (see previous example).  In the data the corrected apparent magnitude is reported in terms of the estimated distance modulus\n",
    "\n",
    "$\\mu = 5 \\log\\left( D_L \\right) - \\mu_o$\n",
    "\n",
    "This assumes a Hubble constant ($D_L \\propto 1/H_o$) and requires a calibration using other distance indicators in local galaxies so there is an additive constant in the distance modulus (or a multiplicative constant to the brightness) that is not very well constrained, i.e. the relative magnitudes of the supernovae are well measured, but not their absolute brightnesses.\n",
    "\n",
    "General relativity and the energy content of the Universe predicts a function for $D_L(z)$ (or $\\mu(z)$) where $z$ is the cosmological redshift of the supernovae.  The relation depends on the density of the universe in matter $\\Omega_{matter}$ and the energy density of the cosmological constant $\\Omega_{\\Lambda}$.  Both are in units of the critical density and must be greater than or equal to 0 and less than or equal to 1.\n",
    "\n",
    "In this tutorial we will make and test some models for $\\mu(z)$.  It will be assumed that the redshifts are very well measured so that their errors do not need to be taken into account (We will also ignore peculiar velocities.) and that the errors in the measured $\\mu(z)$'s are normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Import the data using the command. \n",
    "\n",
    "`data = pa.read_csv(\"SCPUnion2.1_mu_vs_z.txt\",sep='\\t',comment='#')`\n",
    "\n",
    "Note that there are comments starting with \n",
    "\"#\" and the seporators are tabs not commas.\n",
    "\n",
    "Plot the distance modulus vs redshift with error bars and no line connecting the points.  Label the axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pa.read_csv(\"SCPUnion2.1_mu_vs_z.txt\",sep='\\t',comment='#')\n",
    "\n",
    "#data.info()\n",
    "\n",
    "z = data['redshift']\n",
    "mu = data['dist_mod']\n",
    "errors = data['dist_mod_error']\n",
    "plt.errorbar(z,mu,errors, ls='none',capsize=2,elinewidth=0.5)\n",
    "\n",
    "plt.title('')\n",
    "plt.ylabel(r'$\\mu$')\n",
    "plt.xlabel('Z')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Write a function that takes redshift, $\\mu_o$, $\\Omega_m$, $\\Omega_\\Lambda$ and returns $\\mu(z)$.  \n",
    "Use the library function astropy.cosmology.LambdaCDM.luminosity_distance(z).value \n",
    "to calculate the luminosity distance. The Hubble parameter is not separable from $\\mu_o$ so just use $H_o = 70$ in this function.\n",
    "\n",
    "The function should take all the parameters as if they are in a python dictionary.  For example `p['Omega_matter']` for $\\Omega_{matter}$.\n",
    "\n",
    "The parameters p should be :\n",
    "\n",
    "`p['mu_o']` is the absolute magnitude normalization, $\\mu_o$\n",
    "\n",
    "`p['Omega_matter']` is $\\Omega_{matter}$.\n",
    "\n",
    "`p['Omega_lambda']` is $\\Omega_\\Lambda$.\n",
    "\n",
    "This is a nonlinear function of the $\\Omega$'s and a linear function of $\\mu_o$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "import astropy.cosmology as cosmo\n",
    "import numpy as np\n",
    "\n",
    "def mu_function(redshift,p) :\n",
    "    cosmology = cosmo.LambdaCDM(70,p['Omega_matter'].value,p['Omega_lambda'].value)\n",
    "    #dl = np.array(cosmology. ... ))\n",
    "    dl = cosmology. ... .to_value()\n",
    "\n",
    "    return ... + p['mu_o'].value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Write a function that calculates $\\chi^2$ given the data.  It should be a function of `p` only.  Your `mu_function()` should be used inside it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_model = np.zeros_like(z)\n",
    "def my_chi2(p) :\n",
    "    mu_model = mu_function(z,p)\n",
    "    return ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of library functions available to minimize functions including `scipy.optimize.minimize` (which we used in the last exercise) and `scipy.optimize.curve_fit`.  Here we will use a powerful library [`lmfit`](https://lmfit.github.io/lmfit-py/fitting.html#minimizerresult-the-optimization-result) because it will allow us to easily minimize the function while keeping some parameters constant without having to re-write our $\\chi^2$ function.  You might have to install this library with `pip install lmfit`.\n",
    "\n",
    "For this library the the parameters are defined in a tuple of tuples and used like a dictionary.  Each parameter has a name (the same one you used to call it above), an intial value, a boolian flag that determines if that parameter will be varied when optimizing, and then two numbers giving the allowed range.\n",
    "\n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install lmfit\n",
    "import lmfit\n",
    "\n",
    "p = lmfit.Parameters()\n",
    "p.add_many(('Omega_matter',1.0,True,0,1)\n",
    "           ,('Omega_lambda',0.0,True,0,1)\n",
    "           ,('mu_o',24.9,True,10,30))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Use `lmfit.minimize` and the $\\chi^2$ function you wrote above to find the $\\mu_o$ \n",
    "$\\Omega_m$ and $\\Omega_\\Lambda$ that minimize the $\\chi^2$.  Print the best fit parameter values.  \n",
    "Use `method='Nelder'` in `lmfit.minimize`.  Look at the structure it returns to understand how to access the parameter values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fit_result = lmfit.minimize(my_chi2,p,method='Nelder')\n",
    "lmfit.printfuncs.report_fit(best_fit_result.params)\n",
    "\n",
    "## here is how to access the results of the minimization\n",
    "print('best fit value for Omega_matter ',...)\n",
    "print('best fit value for Omega_Lambda ',...)\n",
    "print('best fit chi2 :',...))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Plot the best fit model over the data as already plotted using the functions already defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = np.arange(0.01,1.5,0.01\n",
    "m = ...\n",
    "\n",
    "...\n",
    "\n",
    "plt.ylabel(r'$\\mu$')\n",
    "plt.xlabel('Z')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) At the best fit parameter values, give the p-value and confidence level.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ...\n",
    "\n",
    "print('chi-squared = ',...)\n",
    "print('confidence level = ',...)\n",
    "print('p-value = ',...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Now assume that $\\Omega_\\Lambda = 0$ (no cosmological constant).  What is the best fit $\\Omega_m$ and $m_o$ in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "best_fit_result = ...\n",
    "lmfit.printfuncs.report_fit(best_fit_result.params)\n",
    "\n",
    "print('------------------------------------------------')\n",
    "print('best fit chi2 :',...)\n",
    "print('confidence level = ',...)\n",
    "print('p-value = ',...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Plot in 2 dimensions ($\\Omega_m$ vs $\\mu_o$) the 68%, 95% and 99% confidence regions. (Hint: this will involve creating a new parameter set for each point in the 2D $\\Omega_m$ - $\\mu_o$ and using `lmfit.minimize`.  You also might want to use `method='powell'`)  This may take a little while to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n = ... # number of degrees of freedom\n",
    "\n",
    "cl68 = ...,n)\n",
    "cl95 = ...,n)\n",
    "cl99 = ...,n)\n",
    "\n",
    "print(cl68/n,cl95/n,cl99/n)  # just a test line\n",
    "\n",
    "mus=np.linspace(24.8,25.2,20)\n",
    "omegas=np.linspace(0.01,1.0,20)\n",
    "x2d,y2d = np.meshgrid(mus,omegas)\n",
    "\n",
    "print(len(mus))\n",
    "print(len(omegas))\n",
    "print(x2d.shape)\n",
    "\n",
    "X2 = np.zeros(x2d.shape)\n",
    "for i in range(0,len(mus)) :\n",
    "    for j in range(0,len(omegas)) :\n",
    "        ...\n",
    "        ...\n",
    "        ...\n",
    "        X2[j,i] = ...\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "CS = ax.contour(x2d,y2d,X2,[cl68,cl95,cl99])\n",
    "## the stupidly complicated way contours are labeled \n",
    "fmt = {}\n",
    "strs = [ '68%', '95%', '99%']\n",
    "for i,s in zip( CS.levels, strs ):\n",
    "    fmt[i] = s\n",
    "\n",
    "ax.clabel(CS, inline=True, fontsize=10,fmt=fmt)\n",
    "\n",
    "plt.xlabel(r'$\\mu_o$')\n",
    "plt.ylabel(r'$\\Omega_m$')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Do the same, but for a confidence level plot in the $\\Omega_\\Lambda$ - $\\Omega_m$ plane.  You can reuse a lot of the code from the previous cell.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "omega_m=np.arange(0.01,1.0,0.04)\n",
    "omega_l=np.arange(0.01,1.0,0.04)\n",
    "x2d,y2d = np.meshgrid(omega_m,omega_l)\n",
    "\n",
    "X2 = np.zeros(x2d.shape)\n",
    "\n",
    "....\n",
    "....\n",
    "\n",
    "plt.ylabel(r'$\\Omega_\\Lambda$')\n",
    "plt.xlabel(r'$\\Omega_m$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) We want to find the 68%, 95% and 99% confidence regions for $\\Omega_m$ alone.  First plot $\\chi^2$ as a function of $\\Omega_m$ alone.  Put some horizontal dotted lines at \n",
    "the $\\chi^2$ values for the three confidence levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega_m=np.arange(0.0,1.0,0.02)\n",
    "X2 = np.zeros(len(omega_m))\n",
    "for i in range(0,len(omega_m)) :\n",
    "    ...\n",
    "    ...\n",
    "\n",
    "    X2[i] = ...\n",
    "\n",
    "\n",
    "plt.plot(omega_m,X2)\n",
    "\n",
    "plt.plot([0,1.0], ... ,linestyle=':',label=r'68% cl')\n",
    "plt.plot([0,1.0], ... ,linestyle=':',label=r'95% cl')\n",
    "plt.plot([0,1.0], ... ,linestyle=':',label=r'99% cl')\n",
    "plt.xlim(0,1)\n",
    "plt.xlabel(r'$\\Omega_m$')\n",
    "plt.ylabel(r'$\\chi^2$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11) Now imagine that we know from some other observations that $\\Omega_m=0.5$.  Make the same plot, but for $\\Omega_\\Lambda$ and $\\Omega_m=0.5$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "...\n",
    "\n",
    "plt.plot([0,1.0], ... ,linestyle=':',label=r'68% cl')\n",
    "plt.plot([0,1.0], ... ,linestyle=':',label=r'95% cl')\n",
    "plt.plot([0,1.0], ... ,linestyle=':',label=r'99% cl')\n",
    "plt.xlim(0,1)\n",
    "plt.xlabel(r'$\\Omega_\\Lambda$')\n",
    "plt.ylabel(r'$\\chi^2$')\n",
    "plt.title(r'$\\Omega_m=0.5$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12) What are the 68%, 95% and 99% confidence regions for $\\Omega_\\Lambda$ *given that $\\Omega_m=0.5$*? \n",
    "\n",
    "Taking into account that $0<\\Omega_\\Lambda<1$?  We can find these by finding the ranges in $\\Omega_m$ where the $\\chi^2$ vector created above is the limits (cl68, cl95, cl99)  found before.  (hint: I used numpy.argwhere() for this, but you can do it multiple ways.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "...\n",
    "\n",
    "print('68% confidence level : ', ... ,'< Omega_l <', ... )\n",
    "index = np.argwhere(X2<cl95)\n",
    "print('95% confidence level : ', ... ,'< Omega_l <', ... )\n",
    "index = np.argwhere(X2<cl99)\n",
    "print('99% confidence level : ', ... ,'< Omega_l <', ... )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13) Let us experiment.  We hypothesize that there is an extra source of error in the standard candle correction procedure that was not taken into account.  The standard deviation of this error will be the parameter `p['extra_sig']`.  This error is statistically independent of the errors already given in the data file and normally distributed.  Find the maximum likelihood estimate for this extra parameter.  Minimizing the $\\chi^2$ with respect to `p['extra_sig']` will not work in this case (why?).\n",
    "\n",
    "Write a function that returns the negative of the log of the likelihood ($-\\ln(L)$).  It will be like the $\\chi^2$ function you already wrote.  Minimize it with `lmfit.minimize()`.\n",
    "\n",
    "Is there a significant contribution from this extra source of noise?\n",
    "Would it change the best fit cosmological parameters?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_lnL(p) :\n",
    "    ...\n",
    "    return ...\n",
    "\n",
    "p = lmfit.Parameters()\n",
    "p.add_many(...)            ### in magnitudes\n",
    "\n",
    "best_fit_result = ...\n",
    "lmfit.printfuncs.report_fit(best_fit_result.params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Double click on this and answer the questions:**\n",
    "\n",
    "Why can you not minimize the $\\chi^2$ to find a good estimate for the extra noise?\n",
    "\n",
    "Is there a significant contribution from this extra source of noise?\n",
    "\n",
    "Would the existence of this extra noise change the best fit cosmological parameters?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
